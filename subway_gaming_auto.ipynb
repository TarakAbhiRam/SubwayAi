{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyautogui\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models, transforms\n",
    "from PIL import Image\n",
    "import win32api\n",
    "import win32con\n",
    "import time\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self, num_classes=5):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        # Modify fc1 to match the saved model dimensions\n",
    "        self.fc1 = nn.Linear(64 * 16 * 16, 128)  # Changed to [128, 16384]\n",
    "        self.fc2 = nn.Linear(128, num_classes)   # Changed to [5, 128]\n",
    "        \n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "        x = x.view(-1, 64 * 16 * 16)  # Flatten\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)  # Apply Dropout\n",
    "        x = self.fc2(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ABHIRAM\\AppData\\Local\\Temp\\ipykernel_8952\\1688527614.py:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('D:\\subway\\subway_surfer_model.pth', map_location='cpu'))  # Use 'cpu' or 'cuda'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SimpleCNN(\n",
       "  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (fc1): Linear(in_features=16384, out_features=128, bias=True)\n",
       "  (fc2): Linear(in_features=128, out_features=5, bias=True)\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model = SimpleCNN(5)\n",
    "\n",
    "# Load the model state\n",
    "model.load_state_dict(torch.load('D:\\subway\\subway_surfer_model.pth', map_location='cpu'))  # Use 'cpu' or 'cuda'\n",
    "model.eval()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "\n",
    "# Preprocessing function for the model\n",
    "def preprocess_image(image, device='cpu'):\n",
    "    # Check if the image is a file path or PIL Image\n",
    "    if isinstance(image, str):\n",
    "        image = Image.open(image)  # Open the image if it's a file path\n",
    "\n",
    "    # Define transformation pipeline\n",
    "    transform = transforms.Compose([\n",
    "        transforms.RandomResizedCrop(128),  # Resize images to a smaller size\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "    # Apply transformation and add batch dimension\n",
    "    image = transform(image).unsqueeze(0).to(device)  # Add batch dimension and move to device (CPU/GPU)\n",
    "\n",
    "    return image\n",
    "\n",
    "\n",
    "# Function to press a key\n",
    "def press_key(key_code):\n",
    "    win32api.keybd_event(key_code, 0, 0, 0)  # Key down\n",
    "    time.sleep(0.1)  # Hold the key for a short duration\n",
    "    win32api.keybd_event(key_code, 0, win32con.KEYEVENTF_KEYUP, 0)  # Key up\n",
    "\n",
    "# Key codes for controls\n",
    "key_codes = {\n",
    "    'up': 0x26,    # Up arrow\n",
    "    'down': 0x28,  # Down arrow\n",
    "    'left': 0x25,  # Left arrow\n",
    "    'right': 0x27, # Right arrow\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['down', 'left', 'noop', 'right', 'up']"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes = os.listdir(r'D:\\subway\\SUBWAY\\SUBWAY')\n",
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function keyboard.add_hotkey.<locals>.remove_()>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#hot-key\n",
    "stop_flag = False\n",
    "\n",
    "# Function to stop capturing when 'q' is pressed\n",
    "def stop_capture():\n",
    "    global stop_flag\n",
    "    stop_flag = True\n",
    "\n",
    "# Add a hotkey to stop when 'q' is pressed\n",
    "keyboard.add_hotkey('q', stop_capture)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "lcount,rcount=0,0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyautogui\n",
    "import torch\n",
    "import time\n",
    "import win32api\n",
    "import win32con"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['left', 'right', 'up', 'down', 'noop']  # Add actual class labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def press_key(key_code):\n",
    "    \"\"\"Press and release a key given its virtual key code.\"\"\"\n",
    "    win32api.keybd_event(key_code, 0, 0, 0)  # Press the key\n",
    "    time.sleep(0.1)  # Short delay for key press\n",
    "    win32api.keybd_event(key_code, 0, win32con.KEYEVENTF_KEYUP, 0)  # Release the key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started capturing\n",
      "Rolled (down action)\n",
      "Rolled (down action)\n",
      "Rolled (down action)\n",
      "Rolled (down action)\n",
      "Rolled (down action)\n",
      "Rolled (down action)\n",
      "Rolled (down action)\n",
      "Rolled (down action)\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import pyautogui\n",
    "import win32api\n",
    "import win32con\n",
    "import torch\n",
    "import keyboard\n",
    "\n",
    "# Initialize variables\n",
    "stop_flag = True  # Initialize the stop flag\n",
    "current_lanes = ['left', 'center', 'right']  # Define possible lanes\n",
    "lane = 1  # Start in the center lane (index 1)\n",
    "\n",
    "# Key codes for controls\n",
    "key_codes = {\n",
    "    'up': 0x26,    # Up arrow\n",
    "    'down': 0x28,  # Down arrow\n",
    "    'left': 0x25,  # Left arrow\n",
    "    'right': 0x27, # Right arrow\n",
    "}\n",
    "\n",
    "# Preprocessing function (assumed to be implemented)\n",
    "# def preprocess_image(image): ...\n",
    "\n",
    "while True:\n",
    "    if win32api.GetAsyncKeyState(ord('S')):  # Start capturing when 'S' is pressed\n",
    "        stop_flag = False  # Set the stop flag\n",
    "        print(\"Started capturing\")\n",
    "        lane = 1  # Start in the center lane\n",
    "\n",
    "    while not stop_flag:\n",
    "        # Take a screenshot of the entire screen\n",
    "        screenshot = pyautogui.screenshot()\n",
    "        input_image = preprocess_image(screenshot)\n",
    "\n",
    "        # Perform inference\n",
    "        with torch.no_grad():\n",
    "            output = model(input_image)\n",
    "\n",
    "        # Get the predicted class\n",
    "        _, predicted_class = output.max(1)\n",
    "        action = classes[predicted_class.item()]\n",
    "\n",
    "        if action in key_codes:\n",
    "            # Handle left action\n",
    "            if action == 'left':\n",
    "                if current_lanes[lane] == 'left':\n",
    "                    print(\"Already in the left lane; ignoring left action.\")\n",
    "                else:\n",
    "                    lane -= 1  # Move left\n",
    "                    lane = max(lane, 0)  # Ensure lane doesn't go out of bounds\n",
    "                    press_key(key_codes[action])\n",
    "                    time.sleep(0.1)\n",
    "                    print(f\"Moved left to lane {current_lanes[lane]}\")\n",
    "\n",
    "            # Handle right action\n",
    "            elif action == 'right':\n",
    "                if current_lanes[lane] == 'right':\n",
    "                    print(\"Already in the right lane\")\n",
    "                else:\n",
    "                    lane += 1  # Move right\n",
    "                    lane = min(lane, 2)  # Ensure lane doesn't go out of bounds\n",
    "                    time.sleep(0.2)\n",
    "                    press_key(key_codes[action])\n",
    "                    print(f\"Moved right to lane {current_lanes[lane]}\")\n",
    "\n",
    "            # Handle up action\n",
    "            elif action == 'up':\n",
    "                time.sleep(0.1)\n",
    "                press_key(key_codes[action])\n",
    "                print(\"Jumped (up action)\")\n",
    "\n",
    "            # Handle down action\n",
    "            elif action == 'down':\n",
    "                press_key(key_codes[action])\n",
    "                print(\"Rolled (down action)\")\n",
    "\n",
    "        # Check for no operation\n",
    "        elif action == 'noop':\n",
    "            print(\"No operation performed.\")\n",
    "\n",
    "        # Stop capturing if 'Q' is pressed\n",
    "        if keyboard.is_pressed('q'):\n",
    "            stop_flag = True\n",
    "            print(\"Stopped capturing.\")\n",
    "            break\n",
    "\n",
    "        # Delay to avoid high CPU usage\n",
    "        time.sleep(0.1)\n",
    "\n",
    "    time.sleep(0.1)  # Delay in the main loop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "amazonml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
